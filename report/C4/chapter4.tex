\chapter{A Second Approach : Constraint Based Learning}

As seen in the previous chapter, my initial approach suffered from significant difficulty scaling. Even simple two argument functions took upwards of 400 seconds to complete. This was mainly due to the sheer size of the ground learning task, and the complexity from combinations of rule and where predicates.

\section{Top Down Vs. Bottom Up}
The main issue with the interpreted approach is that it is bottom-up. To learn the output of a rule, it must first iterate down the expression tree (shown in Figure \ref{fig:expr_tree_2}), calculate the value of each simple sub-expression, then iterate back up the tree combining values until a value is known for the entire rule body. My second approach overcomes this issue by implementing a top down approach. \\ \\

\begin{figure}[h!]
\centering
\includegraphics[width=0.55\textwidth]{C1/expression_tree.png}
\caption{Expression tree for a simple expression}
\label{fig:expr_tree_2}
\end{figure}
\mbox{}\\
The idea behind this new approach is simple. By maintaining an ``equality constraint'', the tool keeps track of what each expression is supposed to be equal to (as defined by the input examples). Then, as the program iterates down the expression tree, it fails if it ever finds some easily provable equality failure, i.e 1 = 2. \\ \\
For example, if it knows that \lstinline{call(f, 2) = 5} and that the body of function f is \lstinline{(2 * X) + 1}, then it can deduce that 
\begin{align*}
(2*2) + 1 &= 5 \\
(2*2) &= 4 \\
2 &= 2
\end{align*}
So there are no contradictions. \\ \\
However, if instead there is an example stating that \lstinline{call(f, 2) == 6}, with the same function, then instead we get %{
\begin{align*}
(2*2) + 1 &= 6 \\
(2*2) &= 5 \\
\end{align*}
Which fails because 5 is not a multiple of 2.

\subsection{Dealing with termination}
One issue with this new approach is that it does not automatically handle programs which do not terminate. Whilst these programs do not stop clingo from finding a solution, they are incorrect as the generated constraints never become simple enough to have a contradiction be proved. \\ \\
To deal with this, the tool has to check input examples for termination. While this is typically an undecidable problem, for my small target language it is decidable and computable. To represent this in ASP, there needed to be a way to represent the next step of execution of an expression. For example, we can say that \lstinline{next_step(add(1, mul(2, 3)), mul(2, 3))}, meaning that I next evaluate mul(2, 3). \\ \\%{
I then define termination as :
\begin{itemize}
\item If an expression is simple, containing only constants, then it terminates.
\item If the next step of an expression terminates, then that expression also terminates.
\end{itemize}
\mbox{}\\
This approach is fairly efficient as it as another top down approach, and generates a similar number of rules in the ground program as the constraint checking rules.
\mbox{}\\
\section{ASP Representation}
I represent this approach using the following ASP predicates.

\begin{center}
\begin{tabular}{| c | m{0.7\linewidth} |}
\hline
\textbf{ASP Term} & \textbf{Semantics} \\
\hline
\lstinline!eq(Expr, Val)! 
&
\mbox{}\newline
An equality constraint. Expr, when evaluated, should equal Val. \newline
\\
\hline
\lstinline!is_call(call(F, Expr))!
&
\mbox{}\newline
Represents if a function is called. Used to generate more ground skeleton rules. \newline
\\
\hline
\lstinline!terminates(Expr)! 
&
\mbox{}\newline
Represents if an expression terminates. \newline
\\
\hline
\lstinline!next_step(A, B)!
&
\mbox{}\newline
The next step of the execution of expression A is expression B.\newline
\\
\hline
\end{tabular}
\end{center}
\mbox{}\\
Now, these predicates are used in the following rules. \\

\lstinputlisting[language=Prolog, firstline=32, lastline=32, firstnumber=32, label=lst:eq_gen, caption=Equality generation]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:eq_gen} generates initial equality constraints given by the examples.  \\

\lstinputlisting[language=Prolog, firstline=33, lastline=33, firstnumber=33, label=lst:eq_const, caption=Equality contradiction]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:eq_const} constrains equality on constants. The tool should fail if two different constants are equal. \\

\lstinputlisting[language=Prolog, firstline=34, lastline=37, firstnumber=34, label=lst:eq_const_mul, caption=Multiplication contradictions]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:eq_const_mul} handles edge cases when dealing with multiplication. If multiplying any expression by 0, then it should be equal to 0, and if multiplying two things together, then the answer should be a multiple of them both. \\

\lstinputlisting[language=Prolog, firstline=38, lastline=38, firstnumber=38, label=lst:term_constraint, caption=Termination contradiction]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:term_constraint} handles termination. The tool fails if an input example does not terminate.\\

\lstinputlisting[language=Prolog, firstline=40, lastline=40, firstnumber=40, label=lst:is_call, caption=Is\_call generation]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:is_call} generates \lstinline{is_call} predicates, which are used to generate more ground instances of skeleton rules. \\ %{

\lstinputlisting[language=Prolog, firstline=42, lastline=45, firstnumber=42, label=lst:eq_call, caption=Constraint propagation through function calls]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:eq_call} handles propagation of equality constraints through function calls. If a called function is equal to some value, then the body of the function (with correct arguments) is also equal to that value. \\

\lstinputlisting[language=Prolog, firstline=47, lastline=60, firstnumber=47, label=lst:eq_math, caption=Constraint propagation through arithmetic operations]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:eq_math} specifies generation of equality predicates with arithmetic, through use of the opposite operations. Addition terms in the head of the rule are necessary to handle edge cases such as division by zero. \\

\lstinputlisting[language=Prolog, firstline=62, lastline=63, firstnumber=62, label=lst:eq_pair, caption=Constrain propagation through tuples]{../ASP/eq/eq_rules.lp}
\mbox{}\\
\ref{lst:eq_pair} describes the propagation of equality constraints through tuple pairs. If a tuple of expressions is equal to a tuple of values, then the respective halves of the tuple are equal to each other. \\

\lstinputlisting[language=Prolog, firstline=65, lastline=66, firstnumber=65, label=lst:term, caption=Termination]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:term} defines termination. If an expression is a constant, then it terminates, or if the next step of an expression terminates then that expression also terminates. \\

\lstinputlisting[language=Prolog, firstline=68, lastline=68, firstnumber=68, label=lst:next_init, caption=Next step initialisation]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:next_init} generates the initial \lstinline!next_step! predicates. If there exists an example input, then it is the next step of some arbitrary term \lstinline!e!. \\

\lstinputlisting[language=Prolog, firstline=82, lastline=82, firstnumber=82, label=lst:next_is, caption=Next step grounding improvement]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:next_is} exists to reduce the grounding. If any expression is a next step, we generate an \lstinline{is_next_step} predicate, used in the remaining \lstinline{next_step} rules.\\

\lstinputlisting[language=Prolog, firstline=70, lastline=73, firstnumber=70, label=lst:next_func, caption=Next step propagation through function calls]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:next_func} handles the next step of function calls. The next step of a function call is the body of that function. \\

\lstinputlisting[language=Prolog, firstline=65, lastline=81, firstnumber=65, label=lst:next_match, caption=Next step propagation through arithmetic operations]{../ASP/eq/eq_rules.lp} 
\mbox{} \\
\ref{lst:next_match} generates \lstinline{next_step} predicates for arithmetic and tuples. The next step of an arithmetic expression is the argument that is not constant. %{

\section{Learning}
The actual learning task operates in a similar way to my initial approach. By enumerating all possible rule bodies in the skeleton rules, a choice rule can be used to generate answer sets with each combination of skeleton rule, keeping the answer sets which do not fail the equality constraints. However, because \lstinline!where! rules are no longer being used, the skeleton rules now contain full bodies. This means that unfortunately the number of skeleton rules becomes large, numbering in the thousands for even simple tasks. To avoid this scaling poorly once again, I decided to implement a number of simple optimisations.%{

\subsection{Using inbuilt arithmetic}
As part of my first approach, arithmetic was represented with my own predicates \lstinline{add(A, B)}, \lstinline{sub(A, B)} and \lstinline{mul(A, B)} because the tool needed to evaluate expressions that the grounder would not be able to compute (i.e the value of function calls or where variables). \\ \\ %{
However, in my new approach I decided to make partial use of the clingo inbuilt arithmetic. If inside function arguments, or the rule body has no function calls at all, then the tool knows that all sub expressions will be arithmetic and it can make use of the simple \lstinline{+, -} and \lstinline{*}. \\ \\
The main advantage of this approach is that it vastly reduces the ground output. As the inbuilt operations are computed by the grounder, if two different expressions compute the same output number, then they are not repeated in the ground output. For example, \lstinline{X + X} and \lstinline{2 * X} are semantically equivalent, so when ground with \lstinline!X = 3! both produce the term \lstinline!6!, corresponding to one output rule.

\section{A Worked Example : Greatest common divisor}
Once again I will use Euclid's algorithm for the Greatest Common Divisor \cite{Euclid} to illustrate this new approach. Because the tool still does not have modulo as part of its target language, the simplified definition is used: \\

\lstinputlisting[language=Haskell, firstline=2, lastline=5]{../ASP/eq/gcd.lp} 
\mbox{} \\
As input, I will be using the following examples : \\

\lstinputlisting[language=Prolog, firstline=34, lastline=40]{../ASP/eq/gcd.lp} 
\mbox{} \\
Which cover both cases $(X < Y)$ and $(X > Y)$ while also not being too simplistic. \\ \\
After running the learning task, the resulting Answer Set contains the terms: \\

\begin{lstlisting}
choose(1,2).
choose(2,150, 0).
choose(3,159, 1, 1).
\end{lstlisting}
\mbox{} \\
These terms correspond to the following skeleton rules : \\

\begin{lstlisting}
rule(R, gcd, (N0, N1), N0) :- is_call(call(gcd, (N0, N1))), choose(R, 2). 

rule(R, gcd, (N0, N1), call(gcd, ((N0 - N1), (N1 - 0)))) :- 
		is_call(call(gcd, (N0, N1))), 
		choose(R, 150, 0).

rule(R, gcd, (N0, N1), call(gcd, ((N1 * 1), (N0 * 1)))) :- 
		is_call(call(gcd, (N0, N1))), 
		choose(R, 190).
\end{lstlisting}
\mbox{} \\
Which then corresponds to the Haskell program (simplified for readability):

\begin{lstlisting}
gcd x y
	| x == y = x
	| x > y	 = gcd (x - y) y
	| x < y	 = gcd y x
\end{lstlisting}
\mbox{} \\
What is interesting is that whilst it has not learned the exact target program, the learned program is still correct. This is due to the optimisations preferring rules with shorter bodies.\\ \\
To see why this result is returned, it is useful to look at the corresponding \lstinline{eq} predicates for each example. \\ \\%{
The example \lstinline{example(call(gcd,(8,12)),4)} produces the terms :\\ %{
\begin{multicols}{2}
\begin{lstlisting}
eq(call(gcd,(8,12)),4). 
eq(call(gcd,(12,8)),4).
eq(call(gcd,(4,8)),4).
eq(call(gcd,(8,4)),4).
eq(call(gcd,(4,4)),4).
eq(4, 4).
next_step(e,call(gcd,(8,12))).
next_step(call(gcd,(8,12)),call(gcd,(12,8))).
next_step(call(gcd,(12,8)),call(gcd,(4,8))).
next_step(call(gcd,(4,8)),call(gcd,(8,4))).
next_step(call(gcd,(8,4)),call(gcd,(4,4))).
next_step(call(gcd,(4,4)),4).
\end{lstlisting}
\end{multicols}
\mbox{}\\
Because these terms are all created without constraints failing, the respective rule bodies are returned as a solution.

\section{Performance}
While this new approach does perform better than the old one, it still suffers from a lot of the same issues limiting performance. \\ \\
Because of the large number of combinations of skeleton rules, they can still grow very large very quickly, lowering the performance of my tool. In addition, expanding the language bias to different types also has an adverse effect on this.

\subsection{Reducing the language bias}
As a way to deal with the explosive expansion of skeleton rules, I implemented a way to help contain this by artificially limiting the language bias. \\ \\
By removing operations from the bias that will not be used in the output functions, the tool can remove a large number of skeleton rules that will have no effect on the output of the learning task. In a similar way, learning can be limited to only tail recursive programs, meaning that the skeleton rules only use inbuilt arithmetic operations, further increasing performance. \\ \\
Of course, this method for improving performance is limited by the knowledge of the user. If they have no idea what the output function will look like, this is completely unhelpful, but in many cases they may have even a small idea of what operations will be used. Alternatively, users can iteratively add operations to the background knowledge, starting with a minimal set and gradually increasing it until a valid solution is found.

\pagebreak
\section{Full ASP Listing}
\lstinputlisting[firstline=32, firstnumber=32]{../ASP/eq/eq_rules.lp}

\pagebreak
%\renewcommand\bibname{{References}}
%\bibliography{References}
%\bibliographystyle{plain}